# Arabic Dialect Classification with Synthetic Data and Semi-Supervised Learning

## Abstract 

The lack of labeled data poses significant challenges in training high-performing machine learning models, particularly for Arabic dialects. To address this, we proposed generating synthetic data using large language models (LLMs) and applying a semi-supervised learning approach to utilize unlabeled data. We conducted three experiments: training with real data, a mix of real and synthetic data, and synthetic data only, and compared semi-supervised models against supervised baselines. Semi-supervised models outperformed supervised ones trained on 20\% of the data, and supervised models trained on synthetic data performed within 5.3\% of those trained on 20\% real data. These results demonstrate that semi-supervised learning and synthetic data can address data shortages effectively. Future research could compare the performance of models trained with data generated by different LLMs to determine whether performance can be further improved. Additionally, generating more synthetic data and preparing benchmarks could enhance the evaluation process.


![Screenshot 2024-11-24 000953](https://github.com/user-attachments/assets/15c1d9a5-6118-4832-b8c7-803a168868af)
Figure 1. A parallel workflow for Arabic dialect classification that involves sampling real datasets and generating synthetic data using
prompts, followed by data analysis, evaluation, and testing with different learning methods.


## Objectives
This project investigates the impact of synthetic data generated by Large Language Models (LLMs) on Arabic dialect classification. Specifically, we aim to:
1. Address the **data shortage** using LLM-generated synthetic data.
2. Overcome the **label shortage** using SSL to leverage both labeled and unlabeled data.
3. Evaluate the effectiveness of combining synthetic and real data in improving model performance.

## Research Focus
We focus on classifying five Arabic dialects from the **MADAR dataset** using three main experiments:
1. **Real Data + SSL**: Evaluate the performance of SSL with only real data.
2. **Real + Synthetic Data + SSL**: Combine real data with LLM-generated synthetic data in SSL and test on real data.
3. **Synthetic Data + SSL**: Test SSL using only synthetic data to assess its potential as a substitute for real data.


## Steps to run the code



## Main Results

<img src="https://github.com/user-attachments/assets/953ed38a-3d7b-4446-a51f-b1a41eca05f4" alt="dialects_difff" width="500">


Figure 2. Comparison of Real and Generated Datasets Across Dialects by Training Method and Metric: Each graph illustrates Precision,
Recall, or F1-Score for 100% Supervised, 20% Supervised, and Self-Training methods, highlighting performance differences of average
linear classifiers between Real and Generated datasets across dialects

### Takeaways
1. **Precision**: Real data outperforms generated data in all settings, with smaller gaps in 20% Supervised and Self-Training.
2. **Recall**: Generated data performs competitively, particularly in 20% Supervised and Self-Training.
3. **F1-Score**: Generated data shows near-parity with real data in Self-Training, especially for Gulf and Levantine dialects.
4. **Dialect-Specific**: Egyptian has the best performance, while Maghrebi consistently lags behind.
5. **Overall**: Self-Training effectively bridges the gap between real and generated data.



